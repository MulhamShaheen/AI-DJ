{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-03T14:27:31.120623900Z",
     "start_time": "2023-11-03T14:27:29.368471400Z"
    }
   },
   "outputs": [],
   "source": [
    "from clearml import Task, Logger\n",
    "\n",
    "Task.set_credentials(\n",
    "     api_host=\"https://api.clear.ml\",\n",
    "     web_host=\"https://app.clear.ml\",\n",
    "     files_host=\"https://files.clear.ml\",\n",
    "     key='LDZNDSTURBWF24BBSRTI',\n",
    "     secret='XiGzvdre6QslqIEmzmayua3zukG4M4nSUJyH3gvW3Iw4C9GVJO'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import os\n",
    "from PIL import Image\n",
    "from tempfile import TemporaryDirectory"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T14:27:36.139119800Z",
     "start_time": "2023-11-03T14:27:31.120623900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((244,244)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((244,244)),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = '../data/HAR_2'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=8,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T14:27:46.650429600Z",
     "start_time": "2023-11-03T14:27:45.498291900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with:47.84133434295654 second, num_workers=0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 9\u001B[0m\n\u001B[0;32m      7\u001B[0m start \u001B[38;5;241m=\u001B[39m time()\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m3\u001B[39m):\n\u001B[1;32m----> 9\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_loader, \u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m     10\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m     11\u001B[0m end \u001B[38;5;241m=\u001B[39m time()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AI DJ\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AI DJ\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1328\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1325\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_data(data)\n\u001B[0;32m   1327\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m-> 1328\u001B[0m idx, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1329\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1330\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable:\n\u001B[0;32m   1331\u001B[0m     \u001B[38;5;66;03m# Check for _IterableDatasetStopIteration\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AI DJ\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1284\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._get_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1282\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m   1283\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_thread\u001B[38;5;241m.\u001B[39mis_alive():\n\u001B[1;32m-> 1284\u001B[0m         success, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_try_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1285\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[0;32m   1286\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AI DJ\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1132\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m   1119\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_try_get_data\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m_utils\u001B[38;5;241m.\u001B[39mMP_STATUS_CHECK_INTERVAL):\n\u001B[0;32m   1120\u001B[0m     \u001B[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001B[39;00m\n\u001B[0;32m   1121\u001B[0m     \u001B[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1129\u001B[0m     \u001B[38;5;66;03m# Returns a 2-tuple:\u001B[39;00m\n\u001B[0;32m   1130\u001B[0m     \u001B[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001B[39;00m\n\u001B[0;32m   1131\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1132\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_queue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1133\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n\u001B[0;32m   1134\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1135\u001B[0m         \u001B[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001B[39;00m\n\u001B[0;32m   1136\u001B[0m         \u001B[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001B[39;00m\n\u001B[0;32m   1137\u001B[0m         \u001B[38;5;66;03m# worker failures.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AI DJ\\lib\\queue.py:180\u001B[0m, in \u001B[0;36mQueue.get\u001B[1;34m(self, block, timeout)\u001B[0m\n\u001B[0;32m    178\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m remaining \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m:\n\u001B[0;32m    179\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m Empty\n\u001B[1;32m--> 180\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnot_empty\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mremaining\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    181\u001B[0m item \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get()\n\u001B[0;32m    182\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnot_full\u001B[38;5;241m.\u001B[39mnotify()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AI DJ\\lib\\threading.py:324\u001B[0m, in \u001B[0;36mCondition.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    322\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    323\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 324\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    325\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    326\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m waiter\u001B[38;5;241m.\u001B[39macquire(\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from time import time\n",
    "\n",
    "for num_workers in range(0, mp.cpu_count(), 2):\n",
    "    train_loader = torch.utils.data.DataLoader(image_datasets['train'], batch_size=8,\n",
    "                                             shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    start = time()\n",
    "    for epoch in range(1, 3):\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            pass\n",
    "    end = time()\n",
    "    print(\"Finish with:{} second, num_workers={}\".format(end - start, num_workers))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:15:13.010753900Z",
     "start_time": "2023-11-02T11:13:48.749680100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, history=0):\n",
    "    since = time()\n",
    "\n",
    "\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()\n",
    "                else:\n",
    "                    model.eval()\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "\n",
    "\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                    Logger.current_logger().report_scalar(\n",
    "                        \"train\", \"loss\", iteration=history+epoch, value=epoch_loss\n",
    "                    )\n",
    "                    Logger.current_logger().report_scalar(\n",
    "                        \"train\", \"accuracy\", iteration=history+epoch, value=epoch_acc\n",
    "                    )\n",
    "\n",
    "                elif phase == 'val':\n",
    "                    Logger.current_logger().report_scalar(\n",
    "                        \"test\", \"loss\", iteration=history+epoch, value=epoch_loss\n",
    "                    )\n",
    "                    Logger.current_logger().report_scalar(\n",
    "                        \"test\", \"accuracy\", iteration=history+epoch, value=epoch_acc\n",
    "                    )\n",
    "\n",
    "                    if epoch_acc > best_acc:\n",
    "                        best_acc = epoch_acc\n",
    "                        Logger.current_logger().report_single_value(\"best accuracy\", best_acc)\n",
    "\n",
    "                        torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T14:27:52.119095300Z",
     "start_time": "2023-11-03T14:27:52.089677100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=cb31a6afd19a43269fa6ec92cf34b41a\n",
      "2023-11-03 17:28:33,438 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "ClearML results page: https://app.clear.ml/projects/b3648b77d87c4a8e95218e2aa2d8fe86/experiments/cb31a6afd19a43269fa6ec92cf34b41a/output/log\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'model': 'Vgg11',\n 'loss': 'Cross Entropy',\n 'num_epochs': 10,\n 'optimizer': 'SGD',\n 'scheduler': 'exp_lr_scheduler_5_0.9',\n 'dataset': 'resize v2',\n 'batch': 8,\n 'lr': 0.005}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = Task.init(project_name=\"AI-DJ\", task_name=\"Vgg11 Training\", tags=[\"HAR\"])\n",
    "\n",
    "args = dict(\n",
    "    model = \"Vgg11\",\n",
    "    loss = \"Cross Entropy\",\n",
    "    num_epochs = 10,\n",
    "    optimizer = \"SGD\",\n",
    "    scheduler = \"exp_lr_scheduler_5_0.9\",\n",
    "    dataset = \"resize v2\",\n",
    "    batch = 8,\n",
    "    lr=0.005\n",
    ")\n",
    "\n",
    "task.connect(args)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T14:28:38.747209800Z",
     "start_time": "2023-11-03T14:28:25.428146Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# model = models.vgg11(num_classes=5)\n",
    "# model = model.to(device)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=15, gamma=0.9)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T16:00:31.764051600Z",
     "start_time": "2023-11-03T16:00:31.719053300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 0.9879 Acc: 0.6062\n",
      "val Loss: 1.0921 Acc: 0.5635\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.9734 Acc: 0.6144\n",
      "val Loss: 1.0098 Acc: 0.5940\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.9504 Acc: 0.6215\n",
      "val Loss: 1.0629 Acc: 0.5745\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.9302 Acc: 0.6357\n",
      "val Loss: 1.0321 Acc: 0.5963\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.9043 Acc: 0.6456\n",
      "val Loss: 1.1005 Acc: 0.5687\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.8775 Acc: 0.6535\n",
      "val Loss: 1.0415 Acc: 0.6009\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.8611 Acc: 0.6640\n",
      "val Loss: 1.0032 Acc: 0.6032\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.8400 Acc: 0.6730\n",
      "val Loss: 0.9861 Acc: 0.6101\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.8065 Acc: 0.6911\n",
      "val Loss: 0.9793 Acc: 0.6176\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.7791 Acc: 0.7039\n",
      "val Loss: 0.9595 Acc: 0.6245\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.7462 Acc: 0.7191\n",
      "val Loss: 0.9885 Acc: 0.6314\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.7258 Acc: 0.7258\n",
      "val Loss: 0.9824 Acc: 0.6279\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.6812 Acc: 0.7347\n",
      "val Loss: 1.0364 Acc: 0.6279\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.6512 Acc: 0.7428\n",
      "val Loss: 1.0419 Acc: 0.6210\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.6232 Acc: 0.7646\n",
      "val Loss: 1.3009 Acc: 0.5825\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.5498 Acc: 0.7941\n",
      "val Loss: 1.0698 Acc: 0.6239\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.5204 Acc: 0.8035\n",
      "val Loss: 1.1120 Acc: 0.6308\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.4861 Acc: 0.8185\n",
      "val Loss: 1.1258 Acc: 0.6107\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.4329 Acc: 0.8389\n",
      "val Loss: 1.1551 Acc: 0.6285\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.4217 Acc: 0.8440\n",
      "val Loss: 1.1575 Acc: 0.6354\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.3687 Acc: 0.8662\n",
      "val Loss: 1.2381 Acc: 0.6274\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.3353 Acc: 0.8754\n",
      "val Loss: 1.2292 Acc: 0.6446\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.3040 Acc: 0.8902\n",
      "val Loss: 1.3073 Acc: 0.6366\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.2735 Acc: 0.9008\n",
      "val Loss: 1.3599 Acc: 0.6095\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.2679 Acc: 0.9059\n",
      "val Loss: 1.3733 Acc: 0.6308\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.2324 Acc: 0.9152\n",
      "val Loss: 1.4531 Acc: 0.6205\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.2062 Acc: 0.9267\n",
      "val Loss: 1.6013 Acc: 0.6279\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.1815 Acc: 0.9348\n",
      "val Loss: 1.4986 Acc: 0.6164\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.1720 Acc: 0.9381\n",
      "val Loss: 1.6829 Acc: 0.6337\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.1613 Acc: 0.9416\n",
      "val Loss: 1.5676 Acc: 0.6274\n",
      "\n",
      "Training complete in 96m 42s\n",
      "Best val Acc: 0.644623\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=30, history=20)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T17:37:25.604240300Z",
     "start_time": "2023-11-03T16:00:38.481579100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "task.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T17:37:27.614023Z",
     "start_time": "2023-11-03T17:37:25.610242700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"vgg11/model_50.pt\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T17:37:28.399664Z",
     "start_time": "2023-11-03T17:37:27.631021400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
